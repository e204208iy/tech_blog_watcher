mod feeds;

use feeds::get_feed_sources;

use rss::Channel;
use chrono::{DateTime, Utc, Duration};
use reqwest;
use dotenv::dotenv;
use serde_json::json;
use std::{env, fs, collections::HashSet};
use reqwest::blocking::Client;

const NOTIFIED_URLS_FILE: &str = "notified_urls.txt"; // ä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«

fn main() {
    dotenv().ok();
    let slack_webhook = env::var("SLACK_WEBHOOK_URL").expect("Missing SLACK_WEBHOOK_URL");

    let feed_sources = get_feed_sources();

    let mut notified_urls = load_notified_urls();

    for (company, feed_url) in feed_sources {
        println!("ğŸ” Fetching: {} ({})", company, feed_url);
        if let Ok(channel) = fetch_rss(feed_url) {
            for item in channel.items() {
                let title = item.title().unwrap_or("No title");
                let url = item.link().unwrap_or("No link");

                // pubDateãŒã‚ã‚‹å ´åˆ
                if let Some(pub_date_str) = item.pub_date() {
                    if let Ok(pub_date) = DateTime::parse_from_rfc2822(pub_date_str) {
                        let now = Utc::now();
                        let pub_date_utc = pub_date.with_timezone(&Utc);

                        if now - pub_date_utc < Duration::hours(24) {
                            if notified_urls.insert(url.to_string()) {
                                send_slack_notification(&slack_webhook, company, title, url);
                            } else {
                                println!("âœ… ã™ã§ã«é€šçŸ¥æ¸ˆã¿: {}", title);
                            }
                        } else {
                            println!("ğŸ•°ï¸ å¤ã„è¨˜äº‹ãªã®ã§ã‚¹ã‚­ãƒƒãƒ—: {}", title);
                        }
                    } else {
                        println!("âš ï¸ pubDateãƒ‘ãƒ¼ã‚¹å¤±æ•— â†’ ãƒªãƒ³ã‚¯æ¯”è¼ƒã«åˆ‡ã‚Šæ›¿ãˆ: {}", pub_date_str);
                        notify_if_new(&mut notified_urls, &slack_webhook, company, title, url);
                    }
                } else {
                    println!("âš ï¸ pubDateãªã— â†’ ãƒªãƒ³ã‚¯æ¯”è¼ƒã«åˆ‡ã‚Šæ›¿ãˆ: {}", title);
                    notify_if_new(&mut notified_urls, &slack_webhook, company, title, url);
                }
            }
        }
    }

    save_notified_urls(&notified_urls);
}

// RSSå–å¾—
fn fetch_rss(url: &str) -> Result<Channel, Box<dyn std::error::Error>> {
    let content = reqwest::blocking::get(url)?.bytes()?;
    let channel = Channel::read_from(&content[..])?;
    Ok(channel)
}

// Slacké€šçŸ¥
fn send_slack_notification(webhook_url: &str, company: &str, title: &str, url: &str) {
    let client = Client::new();
    let payload = json!({ "text": format!("ğŸ†• æ–°ç€è¨˜äº‹: {}\n{}\n{}", company, title, url) });

    let res = client
        .post(webhook_url)
        .json(&payload)
        .send()
        .unwrap();

    println!("ğŸ“¢ Slacké€šçŸ¥: {} [{}]", title, res.status());
}

// é€šçŸ¥ã™ã‚‹ã‹åˆ¤æ–­ï¼ˆãƒªãƒ³ã‚¯é‡è¤‡ãƒã‚§ãƒƒã‚¯ï¼‰
fn notify_if_new(notified_urls: &mut HashSet<String>, slack_webhook: &str, company: &str, title: &str, url: &str) {
    if notified_urls.insert(url.to_string()) {
        send_slack_notification(slack_webhook, company, title, url);
    } else {
        println!("âœ… ã™ã§ã«é€šçŸ¥æ¸ˆã¿ï¼ˆpubDateãªã—ï¼‰: {}", title);
    }
}

// ä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰URLãƒªã‚¹ãƒˆèª­ã¿è¾¼ã¿
fn load_notified_urls() -> HashSet<String> {
    match fs::read_to_string(NOTIFIED_URLS_FILE) {
        Ok(content) => content.lines().map(|s| s.to_string()).collect(),
        Err(_) => HashSet::new(),
    }
}

// URLãƒªã‚¹ãƒˆã‚’ä¿å­˜
fn save_notified_urls(urls: &HashSet<String>) {
    let content = urls.iter().cloned().collect::<Vec<_>>().join("\n");
    fs::write(NOTIFIED_URLS_FILE, content).expect("Failed to save notified URLs");
}